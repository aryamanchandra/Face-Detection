{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "951107cd-c9bf-4275-b7fd-83183d082d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, Flatten, Input, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL.Image import Image as pil_image\n",
    "import uuid\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c77644-428d-4325-a5c9-0d32c581b2c3",
   "metadata": {},
   "source": [
    "Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5aeb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "image_preprocess = ImageDataGenerator(\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "test_preprocess = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57aedd13-6715-4ee5-bb1b-c03e8306739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_preprocess.flow_from_directory(\"Face-Images/Final-Training-Images\",\n",
    "                                                     target_size=(64, 64),\n",
    "                                                     batch_size=16,\n",
    "                                                     class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f67b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_preprocess.flow_from_directory(\"Face-Images/Final-Testing-Images\",\n",
    "                                                   target_size=(64, 64),\n",
    "                                                   batch_size=16,\n",
    "                                                   class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d60a47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_classes = train_dataset.class_indices\n",
    "face_id = {value: key for key, value in train_classes.items()}\n",
    "with open(\"faceid.pkl\", 'wb') as file_write_stream:\n",
    "    pickle.dump(face_id, file_write_stream)\n",
    "\n",
    "neurons = len(face_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0703a4-af97-4061-a61b-6add370b6932",
   "metadata": {},
   "source": [
    "CNN Architecture Model for creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced66707-297e-47be-8073-636e6492eb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_architecture():\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "    conv_layer1 = Conv2D(32, (5, 5), activation=\"relu\")(input_layer)\n",
    "    maxpool_layer1 = MaxPooling2D((2, 2), padding=\"same\")(conv_layer1)\n",
    "    conv_layer2 = Conv2D(64, (5, 5), activation=\"relu\")(maxpool_layer1)\n",
    "    maxpool_layer2 = MaxPooling2D((2, 2), padding=\"same\")(conv_layer2)\n",
    "    flatten_layer = Flatten()(maxpool_layer2)\n",
    "    dense_layer1 = Dense(neurons, activation=\"softmax\")(flatten_layer)\n",
    "    return Model(inputs=[input_layer], outputs=[dense_layer1], name=\"feature_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0dab783",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = layer_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a677495-0e43-434b-8f15-83a0d872f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_crossentropy = tf.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d40a64a-99cf-40e8-8c19-9fa868b2b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=optimizer, model=cnn_model)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='accuracy',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "418f7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f5b9bad-ea77-4115-9fad-c38049823bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 58.8457 - accuracy: 0.1118WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 1: accuracy improved from inf to 0.11184, saving model to ./training_checkpoints\\ckpt\n",
      "10/10 [==============================] - 12s 1s/step - loss: 58.8457 - accuracy: 0.1118 - val_loss: 7.9235 - val_accuracy: 0.0455\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.1596 - accuracy: 0.2062\n",
      "Epoch 2: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 4s 351ms/step - loss: 3.1596 - accuracy: 0.2062\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 2.1889 - accuracy: 0.3500\n",
      "Epoch 3: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 2.1889 - accuracy: 0.3500\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.5693 - accuracy: 0.5063\n",
      "Epoch 4: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 1.5693 - accuracy: 0.5063\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9156 - accuracy: 0.7039\n",
      "Epoch 5: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.9156 - accuracy: 0.7039\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.0000 - accuracy: 0.7237\n",
      "Epoch 6: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 1.0000 - accuracy: 0.7237\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7558 - accuracy: 0.7937\n",
      "Epoch 7: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 0.7558 - accuracy: 0.7937\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5899 - accuracy: 0.8375\n",
      "Epoch 8: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 2s 168ms/step - loss: 0.5899 - accuracy: 0.8375\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7150 - accuracy: 0.8158\n",
      "Epoch 9: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.7150 - accuracy: 0.8158\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.8062\n",
      "Epoch 10: accuracy did not improve from 0.11184\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 0.5305 - accuracy: 0.8062\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=10,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=10,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36bbb100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "test_image=load_img(\"Face-Images/Final-Testing-Images/face18/1face18.jpg\",target_size=(64, 64))\n",
    "test_image=img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result = cnn_model.predict(test_image, verbose=0)\n",
    "\n",
    "print(face_id[np.argmax(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a5a68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = test_dataset.next()\n",
    "test_input, test_val = test_batch\n",
    "y_true  = test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3801821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_model.predict([test_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df8f89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dba527b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric1 = Recall()\n",
    "metric1.update_state(y_true,y_pred)\n",
    "metric1.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6636c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric2 = Precision()\n",
    "metric2.update_state(y_true,y_pred)\n",
    "metric2.result().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
